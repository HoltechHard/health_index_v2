{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70bda9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: X(40, 10), y(40,)\n",
      "Train/test split: 32/8 samples\n",
      "\n",
      "==============================\n",
      "Training PCR model\n",
      "==============================\n",
      "Cross-validation R²: -0.888 ± 0.746\n",
      "\n",
      "==============================\n",
      "Training LASSO model\n",
      "==============================\n",
      "Best parameters for LASSO: {'regressor__alpha': 10}\n",
      "Cross-validation R²: -0.232 ± 0.236\n",
      "\n",
      "==============================\n",
      "Training RandomForest model\n",
      "==============================\n",
      "Cross-validation R²: -0.524 ± 0.483\n",
      "\n",
      "Model Performance Comparison:\n",
      "       Model      R²    RMSE\n",
      "         PCR -0.4495 26.7964\n",
      "       LASSO -0.2872 25.2517\n",
      "RandomForest -0.1935 24.3150\n",
      "\n",
      "Results saved to model_comparison.png and model_comparison_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# Configure matplotlib for VS Code display\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def load_data() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load and validate dataset from Excel files.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - X: Feature matrix (n_samples, n_features)\n",
    "        - y: Target vector (n_samples,)\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If data files are missing\n",
    "        ValueError: If data dimensions mismatch\n",
    "    \"\"\"\n",
    "    feature_path = Path(r\"D:\\Desktop\\Pca_LASSO_\\final_40x10.xlsx\")\n",
    "    target_path = Path(r\"D:\\Desktop\\Pca_LASSO_\\Index.xlsx\")\n",
    "\n",
    "    # Validate file existence\n",
    "    if not feature_path.exists():\n",
    "        raise FileNotFoundError(f\"Feature file not found: {feature_path}\")\n",
    "    if not target_path.exists():\n",
    "        raise FileNotFoundError(f\"Target file not found: {target_path}\")\n",
    "\n",
    "    try:\n",
    "        X = pd.read_excel(feature_path, header=None).values\n",
    "        y_df = pd.read_excel(target_path)\n",
    "        y = y_df.iloc[:, 0].values\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading data: {str(e)}\")\n",
    "\n",
    "    # Validate data dimensions\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(f\"Data size mismatch: {len(X)} samples vs {len(y)} targets\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray, model_name: str) -> Dict:\n",
    "    \"\"\"Calculate evaluation metrics for regression models.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth values\n",
    "        y_pred: Predicted values\n",
    "        model_name: Identifier for the model\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing model name and metrics\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"R²\": round(r2_score(y_true, y_pred), 4),\n",
    "        \"RMSE\": round(np.sqrt(mean_squared_error(y_true, y_pred)), 4)\n",
    "    }\n",
    "\n",
    "def plot_results(y_true: np.ndarray, predictions: List[np.ndarray], model_names: List[str]) -> None:\n",
    "    \"\"\"Generate comparison plots for model predictions.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth values\n",
    "        predictions: List of prediction arrays from different models\n",
    "        model_names: List of model identifiers\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6), dpi=100)\n",
    "    \n",
    "    # Prediction vs Actual plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for y_pred, name in zip(predictions, model_names):\n",
    "        plt.scatter(y_true, y_pred, alpha=0.6, label=name, s=40)\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], \n",
    "             'k--', lw=1.5, alpha=0.8)\n",
    "    plt.xlabel(\"Actual Values\", fontsize=12)\n",
    "    plt.ylabel(\"Predicted Values\", fontsize=12)\n",
    "    plt.title(\"Prediction Comparison\", fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Residual distribution plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for y_pred, name in zip(predictions, model_names):\n",
    "        residuals = y_true - y_pred\n",
    "        plt.hist(residuals, bins=15, alpha=0.5, label=name,\n",
    "                 density=True, edgecolor='black')\n",
    "    plt.xlabel(\"Residuals\", fontsize=12)\n",
    "    plt.ylabel(\"Density\", fontsize=12)\n",
    "    plt.title(\"Residual Distribution\", fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"model_comparison.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Main execution workflow\"\"\"\n",
    "    # 1. Data loading and validation\n",
    "    try:\n",
    "        X, y = load_data()\n",
    "        print(f\"Data loaded successfully. Shape: X{X.shape}, y{y.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Data loading failed: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # 2. Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Train/test split: {len(X_train)}/{len(X_test)} samples\")\n",
    "\n",
    "    # 3. Model definitions with proper pipelines\n",
    "    models: Dict = {\n",
    "        \"PCR\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=0.95)),\n",
    "            ('regressor', LinearRegression())\n",
    "        ]),\n",
    "        \"LASSO\": GridSearchCV(\n",
    "            Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', Lasso(max_iter=10000))\n",
    "            ]),\n",
    "            param_grid={'regressor__alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"RandomForest\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=5,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    results: List[Dict] = []\n",
    "    predictions: List[np.ndarray] = []\n",
    "    \n",
    "    # 4. Model training and evaluation\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*30}\\nTraining {name} model\\n{'='*30}\")\n",
    "        \n",
    "        try:\n",
    "            # Handle GridSearchCV separately\n",
    "            if isinstance(model, GridSearchCV):\n",
    "                model.fit(X_train, y_train)\n",
    "                best_params = model.best_params_\n",
    "                print(f\"Best parameters for {name}: {best_params}\")\n",
    "                final_model = model.best_estimator_\n",
    "            else:\n",
    "                final_model = model.fit(X_train, y_train)\n",
    "            \n",
    "            # Generate predictions\n",
    "            y_pred = final_model.predict(X_test)\n",
    "            predictions.append(y_pred)\n",
    "            \n",
    "            # Store results\n",
    "            metrics = evaluate_model(y_test, y_pred, name)\n",
    "            results.append(metrics)\n",
    "            \n",
    "            # Cross-validation (using full pipeline)\n",
    "            cv_scores = cross_val_score(\n",
    "                final_model, X, y, cv=5, \n",
    "                scoring='r2', n_jobs=-1\n",
    "            )\n",
    "            print(f\"Cross-validation R²: {np.mean(cv_scores):.3f} ± {np.std(cv_scores):.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {name} model: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # 5. Results presentation\n",
    "    if results:\n",
    "        result_df = pd.DataFrame(results)\n",
    "        print(\"\\nModel Performance Comparison:\")\n",
    "        print(result_df.to_string(index=False))  # 使用默认文本表格格式\n",
    "        \n",
    "        try:\n",
    "            plot_results(y_test, predictions, list(models.keys()))\n",
    "            result_df.to_excel(\"model_comparison_results.xlsx\", index=False)\n",
    "            print(\"\\nResults saved to model_comparison.png and model_comparison_results.xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {str(e)}\")\n",
    "    else:\n",
    "        print(\"No valid results to display\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
