{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d799e867",
   "metadata": {},
   "source": [
    "### Step 01: ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2193db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned feature column names:\n",
      "['Healthy_People_Domain', 'Difficulties_in_daily_life__Pe_', 'Disability__Pe1_', 'Frailty__Pe1_', 'Mental_health__Pe_', 'Children_s_social__emotional_and_mental_health__Pe2_', 'Mental_health_conditions__Pe2_', 'Self_harm__Pe2_', 'Suicides__Pe2_', 'Mortality__Pe_', 'Avoidable_mortality__Pe3_', 'Infant_mortality__Pe3_', 'Life_expectancy__Pe3_', 'Mortality_from_all_causes__Pe3_', 'Personal_well_being__Pe_', 'Activities_in_life_are_worthwhile__Pe4_', 'Feelings_of_anxiety__Pe4_', 'Happiness__Pe4_', 'Life_satisfaction__Pe4_', 'Physical_health_conditions__Pe_', 'Cancer__Pe5_', 'Cardiovascular_conditions__Pe5_', 'Dementia__Pe5_', 'Diabetes__Pe5_', 'Kidney_and_liver_disease__Pe5_', 'Musculoskeletal_conditions__Pe5_', 'Respiratory_conditions__Pe5_', 'Healthy_Lives_Domain', 'Behavioural_risk_factors__L_', 'Alcohol_misuse__L1_', 'Drug_misuse__L1_', 'Healthy_eating__L1_', 'Physical_activity__L1_', 'Sedentary_behaviour__L1_', 'Sexually_transmitted_infections__L1_', 'Smoking__L1_', 'Children_and_young_people__L_', 'Early_years_development__L2_', 'Pupil_absences__L2_', 'Pupil_attainment__L2_', 'Teenage_pregnancy__L2_', 'Young_people_in_education__employment_and_apprenticeships__L2_', 'Physiological_risk_factors__L_', 'High_blood_pressure__L3_', 'Low_birth_weight__L3_', 'Overweight_and_obesity_in_adults__L3_', 'Overweight_and_obesity_in_children__L3_', 'Protective_measures__L_', 'Cancer_screening_attendance__L4_', 'Child_vaccination_coverage__L4_', 'Healthy_Places_Domain', 'Access_to_green_space__Pl_', 'Private_outdoor_space__Pl1_', 'Access_to_services__Pl_', 'Distance_to_GP_services__Pl2_', 'Distance_to_pharmacies__Pl2_', 'Distance_to_sports_or_leisure_facilities__Pl2_', 'Internet_access__Pl2_', 'Patients_offered_acceptable_GP_practice_appointments__Pl2_', 'Crime__Pl_', 'Low_level_crime__Pl3_', 'Personal_crime__Pl3_', 'Economic_and_working_conditions__Pl_', 'Child_poverty__Pl4_', 'Job_related_training__Pl4_', 'Unemployment__Pl4_', 'Workplace_safety__Pl4_', 'Living_conditions__Pl_', 'Air_pollution__Pl5_', 'Household_overcrowding__Pl5_', 'Noise_complaints__Pl5_', 'Road_safety__Pl5_', 'Rough_sleeping__Pl5_']\n",
      "\n",
      "Total number of samples in dataset: 2387\n",
      "\n",
      "Fold 1\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 1:\n",
      "  Train RMSE: 0.5671, Train R²: 0.9966\n",
      "  Test RMSE: 0.8719, Test R²: 0.9918\n",
      "  Updated best Gradient Boosting model in fold 1 with Test RMSE: 0.8719\n",
      "Random Forest - Fold 1:\n",
      "  Train RMSE: 0.4354, Train R²: 0.9980\n",
      "  Test RMSE: 1.1447, Test R²: 0.9859\n",
      "  Updated best Random Forest model in fold 1 with Test RMSE: 1.1447\n",
      "XGBoost - Fold 1:\n",
      "  Train RMSE: 0.0299, Train R²: 1.0000\n",
      "  Test RMSE: 1.1127, Test R²: 0.9867\n",
      "  Updated best XGBoost model in fold 1 with Test RMSE: 1.1127\n",
      "LightGBM - Fold 1:\n",
      "  Train RMSE: 0.2163, Train R²: 0.9995\n",
      "  Test RMSE: 0.7664, Test R²: 0.9937\n",
      "  Updated best LightGBM model in fold 1 with Test RMSE: 0.7664\n",
      "\n",
      "Fold 2\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 2:\n",
      "  Train RMSE: 0.5214, Train R²: 0.9972\n",
      "  Test RMSE: 0.6853, Test R²: 0.9946\n",
      "  Updated best Gradient Boosting model in fold 2 with Test RMSE: 0.6853\n",
      "Random Forest - Fold 2:\n",
      "  Train RMSE: 0.4380, Train R²: 0.9980\n",
      "  Test RMSE: 0.9641, Test R²: 0.9893\n",
      "  Updated best Random Forest model in fold 2 with Test RMSE: 0.9641\n",
      "XGBoost - Fold 2:\n",
      "  Train RMSE: 0.0288, Train R²: 1.0000\n",
      "  Test RMSE: 0.8520, Test R²: 0.9916\n",
      "  Updated best XGBoost model in fold 2 with Test RMSE: 0.8520\n",
      "LightGBM - Fold 2:\n",
      "  Train RMSE: 0.2201, Train R²: 0.9995\n",
      "  Test RMSE: 0.6511, Test R²: 0.9951\n",
      "  Updated best LightGBM model in fold 2 with Test RMSE: 0.6511\n",
      "\n",
      "Fold 3\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 3:\n",
      "  Train RMSE: 0.5374, Train R²: 0.9969\n",
      "  Test RMSE: 0.8001, Test R²: 0.9934\n",
      "Random Forest - Fold 3:\n",
      "  Train RMSE: 0.4325, Train R²: 0.9980\n",
      "  Test RMSE: 1.1017, Test R²: 0.9874\n",
      "XGBoost - Fold 3:\n",
      "  Train RMSE: 0.0272, Train R²: 1.0000\n",
      "  Test RMSE: 0.9543, Test R²: 0.9906\n",
      "LightGBM - Fold 3:\n",
      "  Train RMSE: 0.2205, Train R²: 0.9995\n",
      "  Test RMSE: 0.7666, Test R²: 0.9939\n",
      "\n",
      "Fold 4\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 4:\n",
      "  Train RMSE: 0.5328, Train R²: 0.9970\n",
      "  Test RMSE: 0.8403, Test R²: 0.9929\n",
      "Random Forest - Fold 4:\n",
      "  Train RMSE: 0.4253, Train R²: 0.9981\n",
      "  Test RMSE: 1.1144, Test R²: 0.9875\n",
      "XGBoost - Fold 4:\n",
      "  Train RMSE: 0.0279, Train R²: 1.0000\n",
      "  Test RMSE: 1.0370, Test R²: 0.9891\n",
      "LightGBM - Fold 4:\n",
      "  Train RMSE: 0.2176, Train R²: 0.9995\n",
      "  Test RMSE: 0.7948, Test R²: 0.9936\n",
      "\n",
      "Fold 5\n",
      "  Training samples: 1908, Test samples: 479\n",
      "Gradient Boosting - Fold 5:\n",
      "  Train RMSE: 0.5244, Train R²: 0.9971\n",
      "  Test RMSE: 1.0026, Test R²: 0.9898\n",
      "Random Forest - Fold 5:\n",
      "  Train RMSE: 0.4156, Train R²: 0.9982\n",
      "  Test RMSE: 1.3991, Test R²: 0.9801\n",
      "XGBoost - Fold 5:\n",
      "  Train RMSE: 0.0258, Train R²: 1.0000\n",
      "  Test RMSE: 1.1769, Test R²: 0.9859\n",
      "LightGBM - Fold 5:\n",
      "  Train RMSE: 0.2169, Train R²: 0.9995\n",
      "  Test RMSE: 0.9945, Test R²: 0.9899\n",
      "Saved best Gradient Boosting model to models\\best_gradient_boosting.pkl\n",
      "Saved best Random Forest model to models\\best_random_forest.pkl\n",
      "Saved best XGBoost model to models\\best_xgboost.pkl\n",
      "Saved best LightGBM model to models\\best_lightgbm.pkl\n",
      "\n",
      "Average Results for Each Model:\n",
      "\n",
      "Gradient Boosting:\n",
      "  Avg Train RMSE: 0.5366\n",
      "  Avg Train R²: 0.9970\n",
      "  Avg Test RMSE: 0.8400\n",
      "  Avg Test R²: 0.9925\n",
      "\n",
      "Random Forest:\n",
      "  Avg Train RMSE: 0.4293\n",
      "  Avg Train R²: 0.9981\n",
      "  Avg Test RMSE: 1.1448\n",
      "  Avg Test R²: 0.9860\n",
      "\n",
      "XGBoost:\n",
      "  Avg Train RMSE: 0.0279\n",
      "  Avg Train R²: 1.0000\n",
      "  Avg Test RMSE: 1.0266\n",
      "  Avg Test R²: 0.9888\n",
      "\n",
      "LightGBM:\n",
      "  Avg Train RMSE: 0.2183\n",
      "  Avg Train R²: 0.9995\n",
      "  Avg Test RMSE: 0.7947\n",
      "  Avg Test R²: 0.9933\n",
      "\n",
      "Generated chart files:\n",
      "- plots\\rmse_comparison.png\n",
      "- plots\\r2_comparison.png\n",
      "- plots\\gradient_boosting_rmse_folds.png\n",
      "- plots\\gradient_boosting_r2_folds.png\n",
      "- plots\\random_forest_rmse_folds.png\n",
      "- plots\\random_forest_r2_folds.png\n",
      "- plots\\xgboost_rmse_folds.png\n",
      "- plots\\xgboost_r2_folds.png\n",
      "- plots\\lightgbm_rmse_folds.png\n",
      "- plots\\lightgbm_r2_folds.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ensure output directories exist\n",
    "plots_dir = 'plots'\n",
    "models_dir = 'models'\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel('../dataset/england_dataset.xlsx')\n",
    "\n",
    "# Data preprocessing\n",
    "# Drop non-numerical or identifier columns\n",
    "X = data.drop(columns=['Area Code', 'Area Name', 'Area Type [Note 3]', 'index health'])\n",
    "y = data['index health']\n",
    "\n",
    "# Clean feature column names: keep only letters, digits, and underscores\n",
    "X.columns = [re.sub(r'[^a-zA-Z0-9]', '_', col) for col in X.columns]\n",
    "# Ensure column names start with a letter (required by LightGBM)\n",
    "X.columns = ['f_' + col if col[0].isdigit() else col for col in X.columns]\n",
    "\n",
    "# Print cleaned column names for debugging\n",
    "print(\"Cleaned feature column names:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "# Handle missing values (fill with 0 for simplicity)\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Validate sample count\n",
    "print(f\"\\nTotal number of samples in dataset: {len(data)}\")\n",
    "if len(data) != 2387:\n",
    "    raise ValueError(\"The dataset should contain 2387 samples. Please check your file!\")\n",
    "\n",
    "# Define manual 5-fold split (477, 477, 477, 477, 479)\n",
    "fold_sizes = [477, 477, 477, 477, 479]\n",
    "fold_indices = []\n",
    "start_idx = 0\n",
    "for fold_size in fold_sizes:\n",
    "    fold_indices.append(range(start_idx, start_idx + fold_size))\n",
    "    start_idx += fold_size\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# Initialize results storage and best models\n",
    "results = {model_name: {'train_rmse': [], 'train_r2': [], 'test_rmse': [], 'test_r2': []} for model_name in models}\n",
    "best_models = {model_name: {'model': None, 'test_rmse': float('inf')} for model_name in models}\n",
    "\n",
    "# Perform manual 5-fold cross-validation\n",
    "for fold_idx, test_indices in enumerate(fold_indices, 1):\n",
    "    print(f\"\\nFold {fold_idx}\")\n",
    "    \n",
    "    test_idx = list(test_indices)\n",
    "    train_idx = [i for i in range(len(data)) if i not in test_idx]\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    print(f\"  Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Clone model to ensure fresh instance\n",
    "        model_instance = type(model)(**model.get_params())\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model_instance.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        y_test_pred = model_instance.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        results[model_name]['train_rmse'].append(train_rmse)\n",
    "        results[model_name]['train_r2'].append(train_r2)\n",
    "        results[model_name]['test_rmse'].append(test_rmse)\n",
    "        results[model_name]['test_r2'].append(test_r2)\n",
    "        \n",
    "        print(f\"{model_name} - Fold {fold_idx}:\")\n",
    "        print(f\"  Train RMSE: {train_rmse:.4f}, Train R²: {train_r2:.4f}\")\n",
    "        print(f\"  Test RMSE: {test_rmse:.4f}, Test R²: {test_r2:.4f}\")\n",
    "        \n",
    "        # Update best model if test RMSE is lower\n",
    "        if test_rmse < best_models[model_name]['test_rmse']:\n",
    "            best_models[model_name]['model'] = model_instance\n",
    "            best_models[model_name]['test_rmse'] = test_rmse\n",
    "            print(f\"  Updated best {model_name} model in fold {fold_idx} with Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Save best models using pickle\n",
    "try:\n",
    "    for model_name in best_models:\n",
    "        model_filename = os.path.join(models_dir, f'best_{model_name.lower().replace(\" \", \"_\")}.pkl')\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(best_models[model_name]['model'], f)\n",
    "        print(f\"Saved best {model_name} model to {model_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving models: {str(e)}\")\n",
    "\n",
    "# Compute average results\n",
    "avg_results = {model_name: {} for model_name in models}\n",
    "for model_name in models:\n",
    "    avg_results[model_name]['avg_train_rmse'] = np.mean(results[model_name]['train_rmse'])\n",
    "    avg_results[model_name]['avg_train_r2'] = np.mean(results[model_name]['train_r2'])\n",
    "    avg_results[model_name]['avg_test_rmse'] = np.mean(results[model_name]['test_rmse'])\n",
    "    avg_results[model_name]['avg_test_r2'] = np.mean(results[model_name]['test_r2'])\n",
    "\n",
    "# Print average results\n",
    "print(\"\\nAverage Results for Each Model:\")\n",
    "for model_name in models:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Avg Train RMSE: {avg_results[model_name]['avg_train_rmse']:.4f}\")\n",
    "    print(f\"  Avg Train R²: {avg_results[model_name]['avg_train_r2']:.4f}\")\n",
    "    print(f\"  Avg Test RMSE: {avg_results[model_name]['avg_test_rmse']:.4f}\")\n",
    "    print(f\"  Avg Test R²: {avg_results[model_name]['avg_test_r2']:.4f}\")\n",
    "\n",
    "# Plot RMSE comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "train_rmse_means = [avg_results[model]['avg_train_rmse'] for model in models]\n",
    "plt.bar(x - width, train_rmse_means, width, label='Avg Train RMSE', color='skyblue')\n",
    "\n",
    "test_rmse_means = [avg_results[model]['avg_test_rmse'] for model in models]\n",
    "plt.bar(x, test_rmse_means, width, label='Avg Test RMSE', color='salmon')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Average RMSE Comparison Across Models')\n",
    "plt.xticks(x, models.keys())\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'rmse_comparison.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot R² comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "train_r2_means = [avg_results[model]['avg_train_r2'] for model in models]\n",
    "plt.bar(x - width, train_r2_means, width, label='Avg Train R²', color='lightgreen')\n",
    "\n",
    "test_r2_means = [avg_results[model]['avg_test_r2'] for model in models]\n",
    "plt.bar(x, test_r2_means, width, label='Avg Test R²', color='orange')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Average R² Comparison Across Models')\n",
    "plt.xticks(x, models.keys())\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'r2_comparison.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot RMSE per fold for each model\n",
    "for model_name in models:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    folds = range(1, 6)\n",
    "    plt.plot(folds, results[model_name]['train_rmse'], marker='o', label='Train RMSE', color='blue')\n",
    "    plt.plot(folds, results[model_name]['test_rmse'], marker='o', label='Test RMSE', color='red')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title(f'{model_name} RMSE per Fold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(plots_dir, f'{model_name.lower().replace(\" \", \"_\")}_rmse_folds.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Plot R² per fold for each model\n",
    "for model_name in models:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    folds = range(1, 6)\n",
    "    plt.plot(folds, results[model_name]['train_r2'], marker='o', label='Train R²', color='green')\n",
    "    plt.plot(folds, results[model_name]['test_r2'], marker='o', label='Test R²', color='orange')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title(f'{model_name} R² per Fold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(plots_dir, f'{model_name.lower().replace(\" \", \"_\")}_r2_folds.png'))\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nGenerated chart files:\")\n",
    "print(f\"- {os.path.join(plots_dir, 'rmse_comparison.png')}\")\n",
    "print(f\"- {os.path.join(plots_dir, 'r2_comparison.png')}\")\n",
    "for model_name in models:\n",
    "    print(f\"- {os.path.join(plots_dir, f'{model_name.lower().replace(' ', '_')}_rmse_folds.png')}\")\n",
    "    print(f\"- {os.path.join(plots_dir, f'{model_name.lower().replace(' ', '_')}_r2_folds.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ebc81",
   "metadata": {},
   "source": [
    "### Step 02: SHAP explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91183a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6c3f0b",
   "metadata": {},
   "source": [
    "Load each model and generate SHAP Explainer for Global Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a6dfd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\POLYTECH_2025\\health_index_v2\\hi_env2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d2f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stored_models(filename, inputs, compute_shap = False):\n",
    "    with open(f'models/{filename}.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    predictions = model.predict(inputs)\n",
    "\n",
    "    if compute_shap:\n",
    "        # Initialize SHAP explainer\n",
    "        explainer = shap.Explainer(model, inputs)\n",
    "        # Compute SHAP values\n",
    "        shap_values = explainer(inputs)\n",
    "        return predictions, shap_values\n",
    "    \n",
    "    return predictions, None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca73cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['best_gradient_boosting', 'best_random_forest', 'best_xgboost', 'best_lightgbm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee059c5",
   "metadata": {},
   "source": [
    "Calculate the predictions and SHAP values for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a158e4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 477/479 [00:37<00:00]        "
     ]
    }
   ],
   "source": [
    "outs = {}\n",
    "shap_outs = {}\n",
    "\n",
    "for model in models:\n",
    "    preds, shaps = load_stored_models(model, X_test, compute_shap= True)\n",
    "\n",
    "    if preds is not None:\n",
    "        outs[model] = preds\n",
    "        shap_outs[model] = shaps\n",
    "    else:\n",
    "        print(\"Error loading computation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bc387",
   "metadata": {},
   "source": [
    "Generate the SHAP Global Explaners graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "236f66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- SHAP Graphics for Model best_gradient_boosting ------\n",
      "Saved SHAP bar plot for best_gradient_boosting to plots\\shap_bar_best_gradient_boosting.png\n",
      "Saved SHAP summary plot for best_gradient_boosting to plots\\shap_summary_best_gradient_boosting.png\n",
      "Saved SHAP heatmap plot for best_gradient_boosting to plots\\shap_heatmap_best_gradient_boosting.png\n",
      "----- SHAP Graphics for Model best_random_forest ------\n",
      "Saved SHAP bar plot for best_random_forest to plots\\shap_bar_best_random_forest.png\n",
      "Saved SHAP summary plot for best_random_forest to plots\\shap_summary_best_random_forest.png\n",
      "Saved SHAP heatmap plot for best_random_forest to plots\\shap_heatmap_best_random_forest.png\n",
      "----- SHAP Graphics for Model best_xgboost ------\n",
      "Saved SHAP bar plot for best_xgboost to plots\\shap_bar_best_xgboost.png\n",
      "Saved SHAP summary plot for best_xgboost to plots\\shap_summary_best_xgboost.png\n",
      "Saved SHAP heatmap plot for best_xgboost to plots\\shap_heatmap_best_xgboost.png\n",
      "----- SHAP Graphics for Model best_lightgbm ------\n",
      "Saved SHAP bar plot for best_lightgbm to plots\\shap_bar_best_lightgbm.png\n",
      "Saved SHAP summary plot for best_lightgbm to plots\\shap_summary_best_lightgbm.png\n",
      "Saved SHAP heatmap plot for best_lightgbm to plots\\shap_heatmap_best_lightgbm.png\n"
     ]
    }
   ],
   "source": [
    "for model in shap_outs:\n",
    "    try:\n",
    "        if shap_outs[model] is not None:\n",
    "            print(f\"----- SHAP Graphics for Model {model} ------\")\n",
    "            # Ensure X_test is a DataFrame for plotting\n",
    "            plot_inputs = X_test if isinstance(X_test, pd.DataFrame) else pd.DataFrame(X_test)\n",
    "            \n",
    "            # Set consistent figure size\n",
    "            plt.figure(figsize=(10, 6))\n",
    "\n",
    "            # 1. Bar Plot (Feature Importance)\n",
    "            shap.plots.bar(shap_outs[model], max_display=12, show=False)\n",
    "            bar_filename = os.path.join(plots_dir, f'shap_bar_{model}.png')\n",
    "            plt.savefig(bar_filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved SHAP bar plot for {model} to {bar_filename}\")\n",
    "\n",
    "            # 2. Summary Plot (Beeswarm)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_outs[model], plot_inputs, show=False)\n",
    "            summary_filename = os.path.join(plots_dir, f'shap_summary_{model}.png')\n",
    "            plt.savefig(summary_filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved SHAP summary plot for {model} to {summary_filename}\")\n",
    "\n",
    "            # 3. Heatmap Plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.plots.heatmap(shap_outs[model], max_display=12, show=False)\n",
    "            heatmap_filename = os.path.join(plots_dir, f'shap_heatmap_{model}.png')\n",
    "            plt.savefig(heatmap_filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved SHAP heatmap plot for {model} to {heatmap_filename}\")\n",
    "        else:\n",
    "            print(f\"No SHAP values available for {model}, skipping plots\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SHAP plots for {model}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f87d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hi_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
