{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e38c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns dtypes:\n",
      "Area Code                           object\n",
      "Healthy People Domain              float64\n",
      "Difficulties in daily life [Pe]    float64\n",
      "Disability [Pe1]                   float64\n",
      "Frailty [Pe1]                      float64\n",
      "                                    ...   \n",
      "Household overcrowding [Pl5]       float64\n",
      "Noise complaints [Pl5]             float64\n",
      "Road safety [Pl5]                  float64\n",
      "Rough sleeping [Pl5]               float64\n",
      "index health                       float64\n",
      "Length: 74, dtype: object\n",
      "Model Performance Summary:\n",
      "\n",
      "Gradient Boosting:\n",
      "Mean Train RMSE: 0.8412\n",
      "Mean Test RMSE: 1.1590\n",
      "Mean Train R²: 0.9931\n",
      "Mean Test R²: 0.9867\n",
      "\n",
      "Random Forest:\n",
      "Mean Train RMSE: 0.4581\n",
      "Mean Test RMSE: 1.2161\n",
      "Mean Train R²: 0.9979\n",
      "Mean Test R²: 0.9854\n",
      "\n",
      "XGBoost:\n",
      "Mean Train RMSE: 0.0931\n",
      "Mean Test RMSE: 1.1375\n",
      "Mean Train R²: 0.9999\n",
      "Mean Test R²: 0.9872\n",
      "\n",
      "LightGBM:\n",
      "Mean Train RMSE: 0.3471\n",
      "Mean Test RMSE: 1.0688\n",
      "Mean Train R²: 0.9988\n",
      "Mean Test R²: 0.9888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "print(\"Numerical columns dtypes:\")\n",
    "print(data[numerical_cols].dtypes)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('D:\\Desktop\\Iteration_1\\dataset\\england_dataset.xlsx')\n",
    "\n",
    "# Define features and target\n",
    "target = 'Life expectancy [Pe3]'\n",
    "# 修改列定义部分\n",
    "categorical_cols = ['Area Name', 'Area Type [Note 3]', 'Area Code']  # 添加实际存在的分类列\n",
    "numerical_cols = [col for col in data.columns \n",
    "                 if col not in categorical_cols + [target]\n",
    "                 and np.issubdtype(data[col].dtype, np.number)]  # 确保只选择数值型列\n",
    "\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = {name: {'train_rmse': [], 'test_rmse': [], 'train_r2': [], 'test_r2': []} for name in models}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Fit model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name]['train_rmse'].append(train_rmse)\n",
    "        results[model_name]['test_rmse'].append(test_rmse)\n",
    "        results[model_name]['train_r2'].append(train_r2)\n",
    "        results[model_name]['test_r2'].append(test_r2)\n",
    "\n",
    "# Aggregate results\n",
    "summary = {}\n",
    "for model_name in models:\n",
    "    summary[model_name] = {\n",
    "        'Mean Train RMSE': np.mean(results[model_name]['train_rmse']),\n",
    "        'Mean Test RMSE': np.mean(results[model_name]['test_rmse']),\n",
    "        'Mean Train R²': np.mean(results[model_name]['train_r2']),\n",
    "        'Mean Test R²': np.mean(results[model_name]['test_r2'])\n",
    "    }\n",
    "\n",
    "# Print summary\n",
    "print(\"Model Performance Summary:\")\n",
    "for model_name, metrics in summary.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10), sharex=True)\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16)\n",
    "\n",
    "# RMSE Plot\n",
    "for i, model_name in enumerate(models):\n",
    "    ax = axes[0, i//2]\n",
    "    folds = range(1, 6)\n",
    "    ax.bar([x - 0.2 for x in folds], results[model_name]['train_rmse'], width=0.4, label='Train RMSE')\n",
    "    ax.bar([x + 0.2 for x in folds], results[model_name]['test_rmse'], width=0.4, label='Test RMSE')\n",
    "    ax.set_title(f'{model_name} RMSE')\n",
    "    ax.set_xlabel('Fold')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    ax.legend()\n",
    "\n",
    "# R² Plot\n",
    "for i, model_name in enumerate(models):\n",
    "    ax = axes[1, i//2]\n",
    "    folds = range(1, 6)\n",
    "    ax.bar([x - 0.2 for x in folds], results[model_name]['train_r2'], width=0.4, label='Train R²')\n",
    "    ax.bar([x + 0.2 for x in folds], results[model_name]['test_r2'], width=0.4, label='Test R²')\n",
    "    ax.set_title(f'{model_name} R²')\n",
    "    ax.set_xlabel('Fold')\n",
    "    ax.set_ylabel('R²')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Summary Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "model_names = list(models.keys())\n",
    "mean_test_rmse = [summary[name]['Mean Test RMSE'] for name in model_names]\n",
    "mean_test_r2 = [summary[name]['Mean Test R²'] for name in model_names]\n",
    "\n",
    "ax1.bar(model_names, mean_test_rmse, color='skyblue')\n",
    "ax1.set_title('Mean Test RMSE Comparison')\n",
    "ax1.set_ylabel('Mean Test RMSE')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax2.bar(model_names, mean_test_r2, color='lightgreen')\n",
    "ax2.set_title('Mean Test R² Comparison')\n",
    "ax2.set_ylabel('Mean Test R²')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('summary_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2193db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned feature column names:\n",
      "['Healthy_People_Domain', 'Difficulties_in_daily_life__Pe_', 'Disability__Pe1_', 'Frailty__Pe1_', 'Mental_health__Pe_', 'Children_s_social__emotional_and_mental_health__Pe2_', 'Mental_health_conditions__Pe2_', 'Self_harm__Pe2_', 'Suicides__Pe2_', 'Mortality__Pe_', 'Avoidable_mortality__Pe3_', 'Infant_mortality__Pe3_', 'Life_expectancy__Pe3_', 'Mortality_from_all_causes__Pe3_', 'Personal_well_being__Pe_', 'Activities_in_life_are_worthwhile__Pe4_', 'Feelings_of_anxiety__Pe4_', 'Happiness__Pe4_', 'Life_satisfaction__Pe4_', 'Physical_health_conditions__Pe_', 'Cancer__Pe5_', 'Cardiovascular_conditions__Pe5_', 'Dementia__Pe5_', 'Diabetes__Pe5_', 'Kidney_and_liver_disease__Pe5_', 'Musculoskeletal_conditions__Pe5_', 'Respiratory_conditions__Pe5_', 'Healthy_Lives_Domain', 'Behavioural_risk_factors__L_', 'Alcohol_misuse__L1_', 'Drug_misuse__L1_', 'Healthy_eating__L1_', 'Physical_activity__L1_', 'Sedentary_behaviour__L1_', 'Sexually_transmitted_infections__L1_', 'Smoking__L1_', 'Children_and_young_people__L_', 'Early_years_development__L2_', 'Pupil_absences__L2_', 'Pupil_attainment__L2_', 'Teenage_pregnancy__L2_', 'Young_people_in_education__employment_and_apprenticeships__L2_', 'Physiological_risk_factors__L_', 'High_blood_pressure__L3_', 'Low_birth_weight__L3_', 'Overweight_and_obesity_in_adults__L3_', 'Overweight_and_obesity_in_children__L3_', 'Protective_measures__L_', 'Cancer_screening_attendance__L4_', 'Child_vaccination_coverage__L4_', 'Healthy_Places_Domain', 'Access_to_green_space__Pl_', 'Private_outdoor_space__Pl1_', 'Access_to_services__Pl_', 'Distance_to_GP_services__Pl2_', 'Distance_to_pharmacies__Pl2_', 'Distance_to_sports_or_leisure_facilities__Pl2_', 'Internet_access__Pl2_', 'Patients_offered_acceptable_GP_practice_appointments__Pl2_', 'Crime__Pl_', 'Low_level_crime__Pl3_', 'Personal_crime__Pl3_', 'Economic_and_working_conditions__Pl_', 'Child_poverty__Pl4_', 'Job_related_training__Pl4_', 'Unemployment__Pl4_', 'Workplace_safety__Pl4_', 'Living_conditions__Pl_', 'Air_pollution__Pl5_', 'Household_overcrowding__Pl5_', 'Noise_complaints__Pl5_', 'Road_safety__Pl5_', 'Rough_sleeping__Pl5_']\n",
      "\n",
      "Total number of samples in dataset: 2387\n",
      "\n",
      "Fold 1\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 1:\n",
      "  Train RMSE: 0.5671, Train R²: 0.9966\n",
      "  Test RMSE: 0.8719, Test R²: 0.9918\n",
      "Random Forest - Fold 1:\n",
      "  Train RMSE: 0.4354, Train R²: 0.9980\n",
      "  Test RMSE: 1.1447, Test R²: 0.9859\n",
      "XGBoost - Fold 1:\n",
      "  Train RMSE: 0.0299, Train R²: 1.0000\n",
      "  Test RMSE: 1.1127, Test R²: 0.9867\n",
      "LightGBM - Fold 1:\n",
      "  Train RMSE: 0.2163, Train R²: 0.9995\n",
      "  Test RMSE: 0.7664, Test R²: 0.9937\n",
      "\n",
      "Fold 2\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 2:\n",
      "  Train RMSE: 0.5214, Train R²: 0.9972\n",
      "  Test RMSE: 0.6853, Test R²: 0.9946\n",
      "Random Forest - Fold 2:\n",
      "  Train RMSE: 0.4380, Train R²: 0.9980\n",
      "  Test RMSE: 0.9641, Test R²: 0.9893\n",
      "XGBoost - Fold 2:\n",
      "  Train RMSE: 0.0288, Train R²: 1.0000\n",
      "  Test RMSE: 0.8520, Test R²: 0.9916\n",
      "LightGBM - Fold 2:\n",
      "  Train RMSE: 0.2201, Train R²: 0.9995\n",
      "  Test RMSE: 0.6511, Test R²: 0.9951\n",
      "\n",
      "Fold 3\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 3:\n",
      "  Train RMSE: 0.5374, Train R²: 0.9969\n",
      "  Test RMSE: 0.8001, Test R²: 0.9934\n",
      "Random Forest - Fold 3:\n",
      "  Train RMSE: 0.4325, Train R²: 0.9980\n",
      "  Test RMSE: 1.1017, Test R²: 0.9874\n",
      "XGBoost - Fold 3:\n",
      "  Train RMSE: 0.0272, Train R²: 1.0000\n",
      "  Test RMSE: 0.9543, Test R²: 0.9906\n",
      "LightGBM - Fold 3:\n",
      "  Train RMSE: 0.2205, Train R²: 0.9995\n",
      "  Test RMSE: 0.7666, Test R²: 0.9939\n",
      "\n",
      "Fold 4\n",
      "  Training samples: 1910, Test samples: 477\n",
      "Gradient Boosting - Fold 4:\n",
      "  Train RMSE: 0.5328, Train R²: 0.9970\n",
      "  Test RMSE: 0.8403, Test R²: 0.9929\n",
      "Random Forest - Fold 4:\n",
      "  Train RMSE: 0.4253, Train R²: 0.9981\n",
      "  Test RMSE: 1.1144, Test R²: 0.9875\n",
      "XGBoost - Fold 4:\n",
      "  Train RMSE: 0.0279, Train R²: 1.0000\n",
      "  Test RMSE: 1.0370, Test R²: 0.9891\n",
      "LightGBM - Fold 4:\n",
      "  Train RMSE: 0.2176, Train R²: 0.9995\n",
      "  Test RMSE: 0.7948, Test R²: 0.9936\n",
      "\n",
      "Fold 5\n",
      "  Training samples: 1908, Test samples: 479\n",
      "Gradient Boosting - Fold 5:\n",
      "  Train RMSE: 0.5244, Train R²: 0.9971\n",
      "  Test RMSE: 1.0026, Test R²: 0.9898\n",
      "Random Forest - Fold 5:\n",
      "  Train RMSE: 0.4156, Train R²: 0.9982\n",
      "  Test RMSE: 1.3991, Test R²: 0.9801\n",
      "XGBoost - Fold 5:\n",
      "  Train RMSE: 0.0258, Train R²: 1.0000\n",
      "  Test RMSE: 1.1769, Test R²: 0.9859\n",
      "LightGBM - Fold 5:\n",
      "  Train RMSE: 0.2169, Train R²: 0.9995\n",
      "  Test RMSE: 0.9945, Test R²: 0.9899\n",
      "\n",
      "Average Results for Each Model:\n",
      "\n",
      "Gradient Boosting:\n",
      "  Avg Train RMSE: 0.5366\n",
      "  Avg Train R²: 0.9970\n",
      "  Avg Test RMSE: 0.8400\n",
      "  Avg Test R²: 0.9925\n",
      "\n",
      "Random Forest:\n",
      "  Avg Train RMSE: 0.4293\n",
      "  Avg Train R²: 0.9981\n",
      "  Avg Test RMSE: 1.1448\n",
      "  Avg Test R²: 0.9860\n",
      "\n",
      "XGBoost:\n",
      "  Avg Train RMSE: 0.0279\n",
      "  Avg Train R²: 1.0000\n",
      "  Avg Test RMSE: 1.0266\n",
      "  Avg Test R²: 0.9888\n",
      "\n",
      "LightGBM:\n",
      "  Avg Train RMSE: 0.2183\n",
      "  Avg Train R²: 0.9995\n",
      "  Avg Test RMSE: 0.7947\n",
      "  Avg Test R²: 0.9933\n",
      "\n",
      "Generated chart files:\n",
      "- rmse_comparison.png\n",
      "- r2_comparison.png\n",
      "- gradient_boosting_rmse_folds.png\n",
      "- gradient_boosting_r2_folds.png\n",
      "- random_forest_rmse_folds.png\n",
      "- random_forest_r2_folds.png\n",
      "- xgboost_rmse_folds.png\n",
      "- xgboost_r2_folds.png\n",
      "- lightgbm_rmse_folds.png\n",
      "- lightgbm_r2_folds.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel('D:\\\\Desktop\\\\Iteration_1\\\\dataset\\\\england_dataset.xlsx')\n",
    "\n",
    "# Data preprocessing\n",
    "# Drop non-numerical or identifier columns\n",
    "X = data.drop(columns=['Area Code', 'Area Name', 'Area Type [Note 3]', 'index health'])\n",
    "y = data['index health']\n",
    "\n",
    "# Clean feature column names: keep only letters, digits, and underscores\n",
    "X.columns = [re.sub(r'[^a-zA-Z0-9]', '_', col) for col in X.columns]\n",
    "# Ensure column names start with a letter (required by LightGBM)\n",
    "X.columns = ['f_' + col if col[0].isdigit() else col for col in X.columns]\n",
    "\n",
    "# Print cleaned column names for debugging\n",
    "print(\"Cleaned feature column names:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "# Handle missing values (fill with 0 for simplicity)\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Validate sample count\n",
    "print(f\"\\nTotal number of samples in dataset: {len(data)}\")\n",
    "if len(data) != 2387:\n",
    "    raise ValueError(\"The dataset should contain 2387 samples. Please check your file!\")\n",
    "\n",
    "# Define manual 5-fold split (477, 477, 477, 477, 479)\n",
    "fold_sizes = [477, 477, 477, 477, 479]\n",
    "fold_indices = []\n",
    "start_idx = 0\n",
    "for fold_size in fold_sizes:\n",
    "    fold_indices.append(range(start_idx, start_idx + fold_size))\n",
    "    start_idx += fold_size\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = {model_name: {'train_rmse': [], 'train_r2': [], 'test_rmse': [], 'test_r2': []} for model_name in models}\n",
    "\n",
    "# Perform manual 5-fold cross-validation\n",
    "for fold_idx, test_indices in enumerate(fold_indices, 1):\n",
    "    print(f\"\\nFold {fold_idx}\")\n",
    "    \n",
    "    test_idx = list(test_indices)\n",
    "    train_idx = [i for i in range(len(data)) if i not in test_idx]\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    print(f\"  Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        y_test_pred = model.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        results[model_name]['train_rmse'].append(train_rmse)\n",
    "        results[model_name]['train_r2'].append(train_r2)\n",
    "        results[model_name]['test_rmse'].append(test_rmse)\n",
    "        results[model_name]['test_r2'].append(test_r2)\n",
    "        \n",
    "        print(f\"{model_name} - Fold {fold_idx}:\")\n",
    "        print(f\"  Train RMSE: {train_rmse:.4f}, Train R²: {train_r2:.4f}\")\n",
    "        print(f\"  Test RMSE: {test_rmse:.4f}, Test R²: {test_r2:.4f}\")\n",
    "\n",
    "# Compute average results\n",
    "avg_results = {model_name: {} for model_name in models}\n",
    "for model_name in models:\n",
    "    avg_results[model_name]['avg_train_rmse'] = np.mean(results[model_name]['train_rmse'])\n",
    "    avg_results[model_name]['avg_train_r2'] = np.mean(results[model_name]['train_r2'])\n",
    "    avg_results[model_name]['avg_test_rmse'] = np.mean(results[model_name]['test_rmse'])\n",
    "    avg_results[model_name]['avg_test_r2'] = np.mean(results[model_name]['test_r2'])\n",
    "\n",
    "# Print average results\n",
    "print(\"\\nAverage Results for Each Model:\")\n",
    "for model_name in models:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Avg Train RMSE: {avg_results[model_name]['avg_train_rmse']:.4f}\")\n",
    "    print(f\"  Avg Train R²: {avg_results[model_name]['avg_train_r2']:.4f}\")\n",
    "    print(f\"  Avg Test RMSE: {avg_results[model_name]['avg_test_rmse']:.4f}\")\n",
    "    print(f\"  Avg Test R²: {avg_results[model_name]['avg_test_r2']:.4f}\")\n",
    "\n",
    "# Plot RMSE comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "train_rmse_means = [avg_results[model]['avg_train_rmse'] for model in models]\n",
    "plt.bar(x - width, train_rmse_means, width, label='Avg Train RMSE', color='skyblue')\n",
    "\n",
    "test_rmse_means = [avg_results[model]['avg_test_rmse'] for model in models]\n",
    "plt.bar(x, test_rmse_means, width, label='Avg Test RMSE', color='salmon')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Average RMSE Comparison Across Models')\n",
    "plt.xticks(x, models.keys())\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('rmse_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot R² comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "train_r2_means = [avg_results[model]['avg_train_r2'] for model in models]\n",
    "plt.bar(x - width, train_r2_means, width, label='Avg Train R²', color='lightgreen')\n",
    "\n",
    "test_r2_means = [avg_results[model]['avg_test_r2'] for model in models]\n",
    "plt.bar(x, test_r2_means, width, label='Avg Test R²', color='orange')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Average R² Comparison Across Models')\n",
    "plt.xticks(x, models.keys())\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('r2_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot RMSE per fold for each model\n",
    "for model_name in models:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    folds = range(1, 6)\n",
    "    plt.plot(folds, results[model_name]['train_rmse'], marker='o', label='Train RMSE', color='blue')\n",
    "    plt.plot(folds, results[model_name]['test_rmse'], marker='o', label='Test RMSE', color='red')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title(f'{model_name} RMSE per Fold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{model_name.lower().replace(\" \", \"_\")}_rmse_folds.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot R² per fold for each model\n",
    "for model_name in models:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    folds = range(1, 6)\n",
    "    plt.plot(folds, results[model_name]['train_r2'], marker='o', label='Train R²', color='green')\n",
    "    plt.plot(folds, results[model_name]['test_r2'], marker='o', label='Test R²', color='orange')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title(f'{model_name} R² per Fold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{model_name.lower().replace(\" \", \"_\")}_r2_folds.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nGenerated chart files:\")\n",
    "print(\"- rmse_comparison.png\")\n",
    "print(\"- r2_comparison.png\")\n",
    "for model_name in models:\n",
    "    print(f\"- {model_name.lower().replace(' ', '_')}_rmse_folds.png\")\n",
    "    print(f\"- {model_name.lower().replace(' ', '_')}_r2_folds.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
